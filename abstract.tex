\chapter*{Abstract}
\markboth{Abstract}{Abstract}
%\addcontentsline{toc}{chapter}{Abstract}
\selectlanguage{english}
\section*{English Abstract}

The task I was given was detecting clothing and shoes in real world images -- the IMP Lab team had previously only trained the algorithms using studio quality images (of shoes).

What I did was use an existing neural network and search for a dataset to train it for detecing clothing on user generated images. This means that the program (for which I created a Command Line Interface) takes as input an image file (or a URL to an image) and returns a processed image; in which annotations such as whether the person is wearing pants, skirts, a dress, footwear or other labels are appended and shown, with a rectangular bounding box and a corresponding mask inside.

The dataset I found is called \modanet, and it is really based on the Paperdoll dataset. \modanet (by eBay researchers) has put annotations to this enormous dataset (about 1 million images)[but only 55k are annotated].

So the work I've done is integrating the dataset with the training algorithm. Fortunately, the \modanet annotations already used COCO's style, but the images were in an SQL database I had to extract (and then put the extraction program into a one-click CLI process!).
Then, I had to create another program that split the annotations into training, validation and test and organize them correctly. The first few weeks were very disappointing and it felt like combining this particular dataset was an impossible feat. It turned out that the lab computer Keras bad installation was also at fault.
Really the first assignment I was given, which I solved relatively quickly, was, using the default image provided and the default weights of \maskrcnn, to cut the image into several segments, each one showing only one object (annotation).

As for the splitting datasets annotations task, I made two revisions. The first one splitted by annotations but left some images in more than one set. So you could have had the same image on different sets but some annotations for that image were in one set and some in the other. This created confusion in the algorithm, but made the task of creating a heterogeneous and balanced training set easier. Second revision was the more classic (I then discovered) approach: putting an image in only one set, and with all its annotations. This made the task of keeping the sets balanced in terms of categories of labels on each set, but I made it!

After completing the first phase (i.e. the "making it work" one), I was advised to create a package for one-click install of the things I had done to make it work.

In the meantime, at dark times when I couldn't go forward without some advising, I let the computer do its things and run the training algorithms. The most I managed to keep it running was about 3-4 days (the computer was shared amongst other researchers and thesists). I managed to reach epoch 28, and I got quite nice results, even though it has a hard time recognizing both feet's footwear most of the time. 

I also made nice customizable viewing commands to see the processed images, and to quickly scan through the validation set (via the --set-all option) to see if the algorithm has improved or not based on your training.

I then fixed a longtime error -- many annotations gave a warning of "invalid indexes" during training because they went outside the images' borders. This way, the dataset got twice as big in an instant, so I decided to redo all the tests.

I then proceeded changing the hyperparameters on the training algorithm to analyze the effect they have on the model's accuracy.


\selectlanguage{italian}
\section*{Italian Abstract}

Il task che ho scelto era di riconoscere vestiti e scarpe in immagini scattate in condizioni naturali -- l'IMP Lab dell'Università con cui ho svolto questa tesi aveva fino ad ora solo addestrato gli algoritmi usando immagini di alta qualità e con sfondo uniforme.

Quello che ho fatto è usare un neural network esistente e cercare un dataset per fargli imparare a riconoscere abbigliamento in immagini generate da persone. Questo significa che il programma (per il quale ho creato una Command Line Interface) prende come input un file di immagine (o l'URL a un'immagine) e ritorna un'immagine processata; nella quale le annotazioni, come per esempio se una persona indossa pantaloni, gonne, un vestito o altri label, sono aggiunte all'immagine e mostrate all'utente. Con un bounding box rettangolare e una maschera corrispondente all'interno.

Il dataset che ho trovato si chiama \modanet, e si basa in realtà su Paperdoll.
\modanet (fatto da ricercatori di eBay) ha annotato più di 50mila immagini (anche se l'intero dataset consiste di quasi un milione di immagini).

Quindi il lavoro che ho fatto è stato integrare il dataset con l'algoritmo di training. Fortunatamente, le annotazioni \modanet seguivano già lo stile COCO, però le immagini erano compresse dentro a un database SQL che ho dovuto estrarre (e poi automatizzare questo processo nella CLI!). Successivamente, ho dovuto creare un altro programma per dividere le annotazioni in training, validation and test set, organizzandole correttamente.
Le prime settimane sono state davvero deludenti e sembrava che il dataset e il training proprio non volessero funzionare insieme. Alla fine abbiamo persino dovuto reinstallare Keras perchè era stato installato male! La prima cosa che mi era stata assegnata l'avevo in realtà risolta in fretta, ovvero dovevo usare un modello (già addestrato dai creatori di \maskrcnn per riconoscere alcuni oggetti in un'immagine) e invece che far vedere l'immagine intera annotata, far vedere soltanto le singole annotazioni una per una.

Per il programma di suddivione delle annotazioni, ho fatto due versioni. La prima le divideva per singole annotazioni, ma permetteva a un'immagine di appartenere a più dataset. Naturalmente con alcune annotazioni di quell'immagine in un set e altre nell'altro. La seconda (che ho poi scoperto essere il metodo classico) le suddivideva per immagini, quindi prendeva un'immagine e la metteva in un set, con tutte le sue annotazioni.

Dopo aver completato la prima fase, mi è stato suggerito di creare un package per permettere a chiunque di installare e rendere pronto all'uso il mio elaborato.
Nel frattempo che io cercavo di risolvere i problemi insormontabili, il computer lavorava per giorni per addestrare l'argoritmo sul dataset. Il massimo che sono riuscito a tenerlo a lavorare è 3-4 giorni (il PC è condiviso con altri tesisti). Sono riuscito a raggiungere l'epoca 28 e ho raggiunto ottimi risultati, nonostante qualche difficolta nel trovare scarpe e footwear.

Ho fatto anche utili comandi per vedere facilmente il risultato dando in pasto immagini manualmente o dal validation set.

Ho poi sistemato un errore che avevamo dato per perso: molte annotazioni venivano buttate via perchè uscivano, seppur di poco, dall'immagine. Dopo aver verificato che le annotazioni "invalide" erano corrette, le abbiamo ridimensionate per farle stare dentro all'immagine. Per questo avevo deciso di rifare i test per vedere i miglioramenti.

Infine, abbiamo modificato gli hyperparameters per l'addestramento per analizzare il loro impatto nell'accuratezza del risultato.



\selectlanguage{english}
